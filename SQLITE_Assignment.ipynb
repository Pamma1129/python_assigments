{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task for today \n",
    "# dataset - https://archive.ics.uci.edu/ml/datasets/Bag+of+words/\n",
    "\n",
    "# Q1 - try to find out count of each and every word in their\n",
    "#      respective files return as [(word, count)]\n",
    "# Q2 - try to perform reduce operation to get a count of all the words\n",
    "#      starting from word and return as [(a,50), (b,40)..]\n",
    "# Q3 - try to filter out all the words from dataset by cleaning\n",
    "#      punctuations \n",
    "# Q4 - create a tuple set of all the records available\n",
    "#      in all the 5 files and then safe strored in SQLITE DB.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging \n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s', \n",
    "                              '%m-%d-%Y %H:%M:%S')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler('logs.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stdout_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "# initialization \n",
    "newList = []\n",
    "# reading a file \n",
    "try: \n",
    "    with open('../Python-Programs/data/vocab.enron.txt', 'r') as f:\n",
    "        rec = f.read()\n",
    "        words = rec.split()\n",
    "        for i in words:\n",
    "            countWord = rec.lower().count(i)\n",
    "            newList.append((i, countWord))\n",
    "except IOError:\n",
    "    print(\"File does not exist\")\n",
    "except Exception as e:\n",
    "    print(\"Program ended with an error \", e)\n",
    "print(newList)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', 62), ('z', 66), ('y', 111), ('q', 135), ('j', 377), ('k', 426), ('v', 469), ('u', 562), ('o', 685), ('n', 768), ('w', 805), ('g', 859), ('l', 989), ('h', 1000), ('i', 1084), ('f', 1160), ('t', 1366), ('e', 1404), ('b', 1557), ('m', 1648), ('d', 1664), ('r', 1723), ('a', 1800), ('p', 1945), ('c', 2611), ('s', 2826)]\n"
     ]
    }
   ],
   "source": [
    "# Q2 \n",
    "# Initialization \n",
    "list_of_letters = set()\n",
    "set_of_words = []\n",
    "listTemp = []\n",
    "\n",
    "try:\n",
    "    # reading a file\n",
    "    with open('../Python-Programs/data/vocab.enron.txt', 'r') as f:\n",
    "        words = f.read()\n",
    "        listOfWords = words.split('\\n')\n",
    "        # it will create unique words as per set\n",
    "        # Get first letter from all the words and put them into bag of set \n",
    "        # data structure to get unique set \n",
    "        for i in listOfWords:\n",
    "            if i != '':\n",
    "                list_of_letters.add(i[0])\n",
    "        # running loop for every character from above formed list\n",
    "        for char in list_of_letters:\n",
    "            # create a list which starts with unique characters from set  \n",
    "            # formed then count its length\n",
    "            for word in words.split():\n",
    "                if word.startswith(char):\n",
    "                    listTemp.append(word)\n",
    "            countOfLetters = len(listTemp)\n",
    "            set_of_words.append((char,countOfLetters))\n",
    "            listTemp = []\n",
    "except Exception as e:\n",
    "    print('Program ended with exception as ', e)\n",
    "except IOError:\n",
    "    print(\"File not found\")\n",
    "# sort the output \n",
    "print(sorted(set_of_words, key = lambda x: x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "# declaring all the punctuations as list\n",
    "punctuation= '''!()-[]{};:'\"\\, <>./?@#$%^&*_~+='''\n",
    "\n",
    "# Initialization\n",
    "newWord = ''\n",
    "listOfWords = []\n",
    "print(\"This program will remove all punctuation [ \"  + punctuation +  \" ] \\\n",
    "        from read file and write it back to new file\")\n",
    "\n",
    "try:\n",
    "    # reading a file\n",
    "    with open('../Python-Programs/data/vocab.pubmed.txt','r') as file:\n",
    "        words = file.read()\n",
    "        for word in words.split('\\n'):\n",
    "            # this is for validating each character of every word and get rid \n",
    "            # of punctuation\n",
    "            for char in word:\n",
    "                if char not in punctuation:\n",
    "                    newWord = newWord + char\n",
    "            if newWord != '':\n",
    "                listOfWords.append(newWord)\n",
    "                newWord = ''\n",
    "except IOError:\n",
    "    print(\"File does not exist\")\n",
    "except Exception as e:\n",
    "    print(\"Program ended with an error \", e)\n",
    "\n",
    "# writing a file \n",
    "with open('../Python-Programs/data/vocab.pubmed.Out.txt','w') as file:\n",
    "    file.write('\\n'.join(listOfWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "# Initialization\n",
    "list_of_all_records = []\n",
    "list_of_no_of_lines = []\n",
    "try:\n",
    "# reading 1st file \n",
    "    with open('../Python-Programs/data/vocab.pubmed.txt','r') as f1:\n",
    "        for count, line in enumerate(f1):\n",
    "            list_of_all_records.append(line.split('\\n')[0])\n",
    "        list_of_no_of_lines.append(count + 1)\n",
    "        # reading 2nd file\n",
    "        with open('../Python-Programs/data/vocab.enron.txt','r') as f2:\n",
    "            for count, line in enumerate(f2):\n",
    "                list_of_all_records.append(line.split('\\n')[0])\n",
    "            list_of_no_of_lines.append(count + 1)\n",
    "            # reading 3rd file\n",
    "            with open('../Python-Programs/data/vocab.kos.txt','r') as f3:\n",
    "                for count, line in enumerate(f3):\n",
    "                    list_of_all_records.append(line.split('\\n')[0])\n",
    "                list_of_no_of_lines.append(count + 1)\n",
    "                # reading 4th file\n",
    "                with open('../Python-Programs/data/vocab.nips.txt','r') as f4:\n",
    "                    for count, line in enumerate(f4):\n",
    "                        list_of_all_records.append(line.split('\\n')[0])\n",
    "                    list_of_no_of_lines.append(count + 1)\n",
    "                    # reading 5th file\n",
    "                    with open('../Python-Programs/data/vocab.nytimes.txt','r') as f5:\n",
    "                        for count, line in enumerate(f5):\n",
    "                            list_of_all_records.append(line.split('\\n')[0])\n",
    "                        list_of_no_of_lines.append(count + 1)\n",
    "except IOError:\n",
    "    print(\"File does not exist\")\n",
    "except Exception as e:\n",
    "    print(\"Program ended with an error \", e)\n",
    "\n",
    "#sum of total number of lines\n",
    "print(sum(list_of_no_of_lines))\n",
    "# list of all records\n",
    "print(list_of_all_records)\n",
    "\n",
    "# generating sequence number list \n",
    "list_of_sequence = [*range(0,sum(list_of_no_of_lines))]\n",
    "# all records from 5 files as tuple\n",
    "all_records_from_files = list(zip(list_of_sequence,list_of_all_records))\n",
    "\n",
    "# just for fun writing whole data to file as string\n",
    "with open('../Python-Programs/data/vocan.all.records.txt','w') as allFile:\n",
    "    allFile.write(str(all_records_from_files))\n",
    "\n",
    "# importing sqlite \n",
    "import sqlite3\n",
    "\n",
    "# create a database\n",
    "db = sqlite3.connect('iNeuron.db')\n",
    "\n",
    "# create cursor \n",
    "cur = db.cursor()\n",
    "\n",
    "# creating a new table \n",
    "cur.execute('create table allRecords(sequence int, data text)')\n",
    "\n",
    "# deleting table's record if any \n",
    "cur.execute('delete from allRecords')\n",
    "\n",
    "# inserting all records in bulk to SQLITE DB\n",
    "for row in all_records_from_files:\n",
    "    seq, data = row\n",
    "    query = \"insert into allRecords values (\" + str(seq) + \",\" + '\"' + data + '\"' + \")\"\n",
    "    cur.execute(query)\n",
    "\n",
    "# getting records from table to see whether records inserted successfully or not \n",
    "records = cur.execute('select * from allRecords')\n",
    "\n",
    "for i in records:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67d8093d4c654d45def0866c1c41478a0f353a2aa0563228ef5b2697cb5e97c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
